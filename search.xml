<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>About us</title>
    <url>/2022/08/30/about%20us/</url>
    <content><![CDATA[<h1 id="who-we-are"><a href="#who-we-are" class="headerlink" title="who we are"></a>who we are</h1><p>Audio &amp; Speech Research Group is a research group under the Key Laboratory of Noise and Vibration Research, Institute of Acoustics, Chinese Academy of Sciences. The Principal Investigator of this research group is Prof. <a href="https://people.ucas.ac.cn/~feiran">Feiran Yang</a> (杨飞然). Our research interests include Adaptive Filtering, Blind Source Separation, Array Signal Processing, Voice Anti-Spoofing, Acoustic Echo Cancellation, Speech Enhancement. See <a href="/categories/">HERE</a></p>
<p>The members of group includes Feiran Yang (杨飞然), Yi Wan (万伊), Taihui Wang (王泰辉), Shengdong Liu (刘升东), Zhengqiang Luo (罗正强), Yang Liu (刘杨), Jinfu Wang (王劲夫), Changtao Li (李长涛), Jing Lei (雷菁), Kelan Kuang (匡柯澜), Qing Shi(石擎), Lan Tang (汤澜), Cong Zhang(张聪), Haobo Jia (贾浩博)</p>
]]></content>
  </entry>
  <entry>
    <title>A Two-Stage Approach to Quality Restoration of Bone-Conducted Speech</title>
    <url>/2023/04/04/two-stage-demo/</url>
    <content><![CDATA[<p>Author: Changtao Li<br>Email: <a href="mailto:&#108;&#x69;&#x63;&#104;&#97;&#110;&#103;&#x74;&#97;&#111;&#64;&#109;&#x61;&#105;&#108;&#x2e;&#x69;&#x6f;&#97;&#46;&#x61;&#x63;&#x2e;&#x63;&#110;">&#108;&#x69;&#x63;&#104;&#97;&#110;&#103;&#x74;&#97;&#111;&#64;&#109;&#x61;&#105;&#108;&#x2e;&#x69;&#x6f;&#97;&#46;&#x61;&#x63;&#x2e;&#x63;&#110;</a></p>
<h1 id="A-Two-Stage-Approach-to-Quality-Restoration-of-Bone-Conducted-Speech"><a href="#A-Two-Stage-Approach-to-Quality-Restoration-of-Bone-Conducted-Speech" class="headerlink" title="A Two-Stage Approach to Quality Restoration of Bone-Conducted Speech"></a>A Two-Stage Approach to Quality Restoration of Bone-Conducted Speech</h1><h2 id="Audio-samples"><a href="#Audio-samples" class="headerlink" title="Audio samples"></a>Audio samples</h2><p>We encourage our readers to listen to the following audio samples in order to experience the audio quality of our enhanced speech.</p>
<table>
  <tbody>
    <tr>
        <th>Signals </th>
        <th>Bone-condcuted speech</th>
        <th>Air-conducted speech</th>
        <th>DPT-EGNet</th>
        <th>Ours</th>
    </tr>
    <tr>
      <td>sample 1</td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/bc_4.wav?raw=true" controls></td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/ac_4.wav?raw=true" controls></td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/sample4.wav?raw=true" controls></td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/ac_pred_4.wav?raw=true" controls></td>
    </tr>
    <tr>
      <td>sample 2</td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/bc_5.wav?raw=true" controls></td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/ac_5.wav?raw=true" controls></td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/sample5.wav?raw=true" controls></td>      
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/ac_pred_5.wav?raw=true" controls></td>
    </tr>
    <tr>
      <td>sample 3</td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/bc_11.wav?raw=true" controls></td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/ac_11.wav?raw=true" controls></td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/sample11.wav?raw=true" controls></td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/ac_pred_11.wav?raw=true" controls></td>
    </tr>
    <tr>
      <td>sample 4</td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/bc_13.wav?raw=true" controls></td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/ac_13.wav?raw=true" controls></td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/sample13.wav?raw=true" controls></td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/ac_pred_13.wav?raw=true" controls></td>
    </tr>
    <tr>
      <td>sample 5</td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/bc_14.wav?raw=true" controls></td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/ac_14.wav?raw=true" controls></td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/sample14.wav?raw=true" controls></td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/ac_pred_14.wav?raw=true" controls></td>
    </tr>
    <tr>
      <td>sample 6</td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/bc_18.wav?raw=true" controls></td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/ac_18.wav?raw=true" controls></td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/sample18.wav?raw=true" controls></td>
      <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/ac_pred_18.wav?raw=true" controls></td>
    </tr>
    <tr>
        <td>sample 7</td>
        <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/bc_1.wav?raw=true" controls></td>
        <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/ac_1.wav?raw=true" controls></td>
        <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/sample1.wav?raw=true" controls></td>
        <td><audio src="https://github.com/changtaoli/two-stage-approach-audios/blob/main/ac_pred_1.wav?raw=true" controls></td>
    </tr>
  </tbody>
  <colgroup>
    <col style="width: 5%;">
    <col style="width: 5%;">
    <col style="width: 5%;">
    <col style="width: 5%;">
  </colgroup>
</table>



















<h2 id="More-samples"><a href="#More-samples" class="headerlink" title="More samples"></a>More samples</h2><p>For more samples,  See <a href="https://github.com/changtaoli/two-stage-approach-audios">https://github.com/changtaoli/two-stage-approach-audios</a></p>
]]></content>
      <categories>
        <category>Speech Enhancement</category>
      </categories>
      <tags>
        <tag>Deep Neural Network</tag>
        <tag>Bone-conducted Speech Enhancement</tag>
      </tags>
  </entry>
  <entry>
    <title>CTF-MNMF demo</title>
    <url>/2023/03/27/CTFMNMF_demo/</url>
    <content><![CDATA[<p>作者: Taihui Wang<br>Email: <a href="mailto:&#119;&#97;&#x6e;&#x67;&#x74;&#97;&#105;&#104;&#117;&#x69;&#x40;&#x6d;&#97;&#105;&#x6c;&#x2e;&#x69;&#111;&#x61;&#x2e;&#x61;&#99;&#46;&#x63;&#x6e;">&#119;&#97;&#x6e;&#x67;&#x74;&#97;&#105;&#104;&#117;&#x69;&#x40;&#x6d;&#97;&#105;&#x6c;&#x2e;&#x69;&#111;&#x61;&#x2e;&#x61;&#99;&#46;&#x63;&#x6e;</a></p>
<h1 id="Convolutive-Transfer-Function-Based-Multichannel-Nonnegative-Matrix-Factorization-for-Overdetermined-Blind-Source-Separation"><a href="#Convolutive-Transfer-Function-Based-Multichannel-Nonnegative-Matrix-Factorization-for-Overdetermined-Blind-Source-Separation" class="headerlink" title="Convolutive Transfer Function-Based Multichannel Nonnegative Matrix Factorization for Overdetermined Blind Source Separation"></a>Convolutive Transfer Function-Based Multichannel Nonnegative Matrix Factorization for Overdetermined Blind Source Separation</h1><p>Taihui Wang <sup>1</sup><sup>, 2</sup>  , Feiran Yang <sup>3</sup>  , Member, IEEE, and Jun Yang <sup>1</sup><sup>, 2</sup>  , Senior Member, IEEE</p>
<p><sup>1</sup>  Key Laboratory of Noise and Vibration Research, Institute of Acoustics, Chinese Academy of Sciences, Beijing,<br>China</p>
<p> <sup>2</sup> University of Chinese Academy of Sciences, Beijing, China</p>
<p> <sup>3</sup> State Key Laboratory of Acoustics, Institute of Acoustics, Chinese Academy of Sciences, Beijing, China</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Most multichannel blind source separation (BSS) approaches rely on a spatial model to encode the transfer functions from sources to microphones and a source model to encode the source power spectral density. The rank-1 spatial model has been widely exploited in independent component analysis (ICA), independent vector analysis (IVA), and independent low-rank matrix analysis (ILRMA). The full-rank spatial model is also considered in many BSS approaches, such as full-rank spatial covariance matrix analysis (FCA), multichannel nonnegative matrix factorization (MNMF), and FastMNMF, which can improve the separation performance in the case of long reverberation times. This paper proposes a new MNMF framework based on the convolutive transfer function (CTF) for overdetermined BSS. The time-domain convolutive mixture model is approximated by a frequency-wise convolutive mixture model instead of the widely adopted frequency-wise instantaneous mixture model. The iterative projection algorithm is adopted to estimate the demixing matrix, and the multiplicative update rule is employed to estimate nonnegative matrix factorization (NMF) parameters. Finally, the source image is reconstructed using a multichannel Wiener filter. The advantages of the proposed method are twofold. First, the CTF approximation enables us to use a short window to represent long impulse responses. Second, the full-rank spatial model can be derived based on the CTF approximation and slowly time-variant source variances, and close relationships between the proposed method and ILRMA, FCA, MNMF and FastMNMF are revealed. Extensive experiments show that the proposed algorithm achieves a higher separation performance than ILRMA and FastMNMF in reverberant environments.</p>
<h2 id="Separated-audio-samples"><a href="#Separated-audio-samples" class="headerlink" title="Separated audio samples"></a>Separated audio samples</h2><p>The following table shows an example of the 2-music source separation task, where the public NMF model is used and the number of bases is set to 32.  The reverberation time is 470 ms, and the channel number is 6. </p>
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-baqh{text-align:center;vertical-align:top}
.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-0pky"></th>
    <th class="tg-c3ow">Source 1</th>
    <th class="tg-c3ow">Source 2</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-c3ow">Clean reverberant sources</td>
    <td class="tg-c3ow"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/musicSignals/2-musicSourceUsing6micsWithReverberationTime470ms/image1.wav?raw=true" controls></td>
    <td class="tg-c3ow"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/musicSignals/2-musicSourceUsing6micsWithReverberationTime470ms/image2.wav?raw=true" controls></td>
  </tr>
  <tr>
    <td class="tg-c3ow">Mixture at the first microphone</td>
    <td class="tg-c3ow" colspan="2"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/musicSignals/2-musicSourceUsing6micsWithReverberationTime470ms/mixture.wav?raw=true" controls></td>
  </tr>
  <tr>
    <td class="tg-baqh">Separated sources uing CTF-MNMF</td>
    <td class="tg-baqh"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/musicSignals/2-musicSourceUsing6micsWithReverberationTime470ms/sep1UsingCTFMNMF-SDR.wav?raw=true" controls></td>
    <td class="tg-baqh"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/musicSignals/2-musicSourceUsing6micsWithReverberationTime470ms/sep2UsingCTFMNMF-SDR.wav?raw=true" controls></td>
  </tr>
</tbody>
</table>


<span id="more"></span>



<p>The following table shows an example of the 2-speech source separation task, where the private NMF model is used and the number of bases is set to 2.  The reverberation time is 470 ms, and the channel number is 6.</p>
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-baqh{text-align:center;vertical-align:top}
.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-0pky"></th>
    <th class="tg-c3ow">Source 1</th>
    <th class="tg-c3ow">Source 2</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-c3ow">Clean reverberant sources</td>
    <td class="tg-c3ow"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/speechSignals/2-speechSourceUsing6micsWithReverberationTime470ms/image1.wav?raw=true" controls></td>
    <td class="tg-c3ow"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/speechSignals/2-speechSourceUsing6micsWithReverberationTime470ms/image2.wav?raw=true" controls></td>
  </tr>
  <tr>
    <td class="tg-c3ow">Mixture at the first microphone</td>
    <td class="tg-c3ow" colspan="2"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/speechSignals/2-speechSourceUsing6micsWithReverberationTime470ms/mixture.wav?raw=true" controls></td>
  </tr>
  <tr>
    <td class="tg-baqh">Separated sources uing CTF-MNMF</td>
    <td class="tg-baqh"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/speechSignals/2-speechSourceUsing6micsWithReverberationTime470ms/separated1.wav?raw=true" controls></td>
    <td class="tg-baqh"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/speechSignals/2-speechSourceUsing6micsWithReverberationTime470ms/separated2.wav?raw=true" controls></td>
  </tr>
</tbody>
</table>

<p>The following table shows an example of the 2-speech source separation task, where the private NMF model is used and the number of bases is set to 2.  The reverberation time is 1300 ms, and the channel number is 6.</p>
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-baqh{text-align:center;vertical-align:top}
.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-0pky"></th>
    <th class="tg-c3ow">Source 1</th>
    <th class="tg-c3ow">Source 2</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-c3ow">Clean reverberant sources</td>
    <td class="tg-c3ow"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/speechSignals/2-speechSourceUsing6micsWithReverberationTime1300ms/image1.wav?raw=true" controls></td>
    <td class="tg-c3ow"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/speechSignals/2-speechSourceUsing6micsWithReverberationTime1300ms/image2.wav?raw=true" controls></td>
  </tr>
  <tr>
    <td class="tg-c3ow">Mixture at the first microphone</td>
    <td class="tg-c3ow" colspan="2"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/speechSignals/2-speechSourceUsing6micsWithReverberationTime1300ms/mixture.wav?raw=true" controls></td>
  </tr>
  <tr>
    <td class="tg-baqh">Separated sources uing CTF-MNMF</td>
    <td class="tg-baqh"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/speechSignals/2-speechSourceUsing6micsWithReverberationTime1300ms/separated1.wav?raw=true" controls></td>
    <td class="tg-baqh"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/speechSignals/2-speechSourceUsing6micsWithReverberationTime1300ms/separated2.wav?raw=true" controls></td>
  </tr>
</tbody>
</table>



<p>The following table shows an example of the 4- speech source separation tast, where the private NMF model is used and the number of bases is set to 2.  The reverberation time is 470 ms, and the channel number is 8.</p>
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-0p91{border-color:inherit;font-family:"Times New Roman", Times, serif !important;text-align:center;vertical-align:top}
.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
.tg .tg-iucd{border-color:inherit;font-family:"Times New Roman", Times, serif !important;text-align:left;vertical-align:top}
.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-iucd"></th>
    <th class="tg-c3ow">Source 1</th>
    <th class="tg-c3ow">Source 2</th>
    <th class="tg-0pky">Source 3</th>
    <th class="tg-0pky">Source 4</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0p91">Clean sources</td>
    <td class="tg-c3ow"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/speechSignals/4-speechSourceUsing8micsWithReverberationTime470ms/image1.wav?raw=true" controls></td>
    <td class="tg-c3ow"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/speechSignals/4-speechSourceUsing8micsWithReverberationTime470ms/image2.wav?raw=true" controls></td>
    <td class="tg-0pky"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/speechSignals/4-speechSourceUsing8micsWithReverberationTime470ms/image3.wav?raw=true" controls></td>
    <td class="tg-0pky"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/speechSignals/4-speechSourceUsing8micsWithReverberationTime470ms/image4.wav?raw=true" controls></td>
  </tr>
  <tr>
    <td class="tg-0p91">Mixture at the first microphone</td>
    <td class="tg-c3ow" colspan="4"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/speechSignals/4-speechSourceUsing8micsWithReverberationTime470ms/mixture.wav?raw=true" controls></td>
  </tr>
  <tr>
    <td class="tg-0p91">Separated sources uing CTF-MNMF</td>
    <td class="tg-c3ow"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/speechSignals/4-speechSourceUsing8micsWithReverberationTime470ms/sep1UsingCTFMNMF-SDR.wav?raw=true" controls></td>
    <td class="tg-c3ow"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/speechSignals/4-speechSourceUsing8micsWithReverberationTime470ms/sep2UsingCTFMNMF-SDR.wav?raw=true" controls></td>
    <td class="tg-0pky"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/speechSignals/4-speechSourceUsing8micsWithReverberationTime470ms/sep3UsingCTFMNMF-SDR.wav?raw=true" controls></td>
    <td class="tg-0pky"><audio src="https://github.com/TaihuiWang/SeparatedAudioSamplesUsingCTF-MNMF/blob/main/speechSignals/4-speechSourceUsing8micsWithReverberationTime470ms/sep4UsingCTFMNMF-SDR.wav?raw=true" controls></td>
  </tr>
</tbody>
</table>
## Other samples

<p>For more audio samples, the reader is referred to <a href="https://github.com/TaihuiWang/CTF-MNMF">TaihuiWang/CTF-MNMF (github.com)</a></p>
]]></content>
      <categories>
        <category>Blind Source Separation</category>
      </categories>
      <tags>
        <tag>Blind Source Separation</tag>
        <tag>Nonnegative Matrix Analysis</tag>
        <tag>Convolutive Transfer function</tag>
        <tag>Spatial Covariance Matrix</tag>
      </tags>
  </entry>
  <entry>
    <title>TriU-Net demo</title>
    <url>/2023/03/20/TriU-Net_demo/</url>
    <content><![CDATA[<p>作者: Kelan Kuang<br>Email: <a href="mailto:&#x6b;&#x75;&#97;&#x6e;&#x67;&#107;&#101;&#x6c;&#x61;&#x6e;&#x40;&#109;&#x61;&#x69;&#108;&#x2e;&#x69;&#111;&#97;&#46;&#x61;&#99;&#x2e;&#99;&#x6e;">&#x6b;&#x75;&#97;&#x6e;&#x67;&#107;&#101;&#x6c;&#x61;&#x6e;&#x40;&#109;&#x61;&#x69;&#108;&#x2e;&#x69;&#111;&#97;&#46;&#x61;&#99;&#x2e;&#99;&#x6e;</a></p>
<h1 id="Multi-Channel-Speech-Enhancement-results"><a href="#Multi-Channel-Speech-Enhancement-results" class="headerlink" title="Multi-Channel Speech Enhancement results"></a>Multi-Channel Speech Enhancement results</h1><p>This repo shows enhanced speech of TriU-Net and other models.</p>
<h2 id="Real-recordings"><a href="#Real-recordings" class="headerlink" title="Real recordings"></a>Real recordings</h2><p>SNR: -5 dB</p>
<p>Spk 1 is a 24-year-old male, while spk 2 is a 24-year-old female. Both spk 1 and spk 2 speek in Mandarin. </p>
<table>
  <tbody>
    <tr>
        <th>Signals </th>
        <th>Spk 1 babble</th>
        <th>Spk 2 babble</th>
        <th>Spk 1 f16</th>
        <th>Spk 2 f16</th>
    </tr>
    <tr>
      <td>noisy</td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/9ULA_synth_kkl_babble_snr-5.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk1/babble/9ULA_synth_kkl_babble_snr-5.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/9ULA_synth_yzh_babble_snr-5.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk2/babble/9ULA_synth_yzh_babble_snr-5.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/9ULA_synth_kkl_babble_snr-5.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk1/f16/9ULA_synth_kkl_f16_snr-5.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/9ULA_synth_yzh_f16_snr-5.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk2/f16/9ULA_synth_yzh_f16_snr-5.wav" controls></td>
    </tr>
    <tr>
      <td>clean</td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/9ULA_kkl_clean.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk1/babble/9ULA_kkl_clean.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/9ULA_yzh_clean.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk2/babble/9ULA_yzh_clean.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/9ULA_kkl_clean.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk1/f16/9ULA_kkl_clean.wav" controls></td>      
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/9ULA_yzh_clean.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk2/f16/9ULA_yzh_clean.wav" controls></td>
    </tr>
    <tr>
      <td>oracl MB-MVDR</td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/real_enh_oracle_MBMVDR_kkl_babble_snr-5_pesq1.09_1.36.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk1/babble/real_enh_oracle_MBMVDR_kkl_babble_snr-5_pesq1.09_1.36.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/real_enh_oracle_MBMVDR_yzh_babble_snr-5_pesq1.06_1.27.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk2/babble/real_enh_oracle_MBMVDR_yzh_babble_snr-5_pesq1.06_1.27.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/real_enh_oracle_MBMVDR_kkl_f16_snr-5_pesq1.06_1.3.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk1/f16/real_enh_oracle_MBMVDR_kkl_f16_snr-5_pesq1.06_1.3.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/real_enh_oracle_MBMVDR_yzh_f16_snr-5_pesq1.04_1.25.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk2/f16/real_enh_oracle_MBMVDR_yzh_f16_snr-5_pesq1.04_1.25.wav" controls></td>
    </tr>
    <tr>
      <td>EaBNet</td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/real_enh_EaBNet_kkl_babble_snr-5_pesq1.09_1.27.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk1/babble/real_enh_EaBNet_kkl_babble_snr-5_pesq1.09_1.27.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/real_enh_EaBNet_yzh_babble_snr-5_pesq1.06_1.33.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk2/babble/real_enh_EaBNet_yzh_babble_snr-5_pesq1.06_1.33.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/real_enh_EaBNet_kkl_f16_snr-5_pesq1.06_1.37.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk1/f16/real_enh_EaBNet_kkl_f16_snr-5_pesq1.06_1.37.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/real_enh_EaBNet_yzh_f16_snr-5_pesq1.04_1.41.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk2/f16/real_enh_EaBNet_yzh_f16_snr-5_pesq1.04_1.41.wav" controls></td>
    </tr>
    <tr>
      <td>FaSNet</td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/real_enh_FaSNet_kkl_babble_snr-5_pesq1.09_1.24.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk1/babble/real_enh_FaSNet_kkl_babble_snr-5_pesq1.09_1.24.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/real_enh_FaSNet_yzh_babble_snr-5_pesq1.06_1.23.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk2/babble/real_enh_FaSNet_yzh_babble_snr-5_pesq1.06_1.23.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/real_enh_FaSNet_kkl_f16_snr-5_pesq1.06_1.35.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk1/f16/real_enh_FaSNet_kkl_f16_snr-5_pesq1.06_1.35.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/real_enh_FaSNet_yzh_f16_snr-5_pesq1.04_1.47.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk2/f16/real_enh_FaSNet_yzh_f16_snr-5_pesq1.04_1.47.wav" controls></td>
    </tr>
    <tr>
      <td>Model A</td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/real_enh_ModelA_kkl_babble_snr-5_pesq1.09_1.42.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk1/babble/real_enh_ModelA_kkl_babble_snr-5_pesq1.09_1.42.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/real_enh_ModelA_yzh_babble_snr-5_pesq1.06_1.26.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk2/babble/real_enh_ModelA_yzh_babble_snr-5_pesq1.06_1.26.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/real_enh_ModelA_kkl_f16_snr-5_pesq1.06_1.6.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk1/f16/real_enh_ModelA_kkl_f16_snr-5_pesq1.06_1.6.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/real_enh_ModelA_yzh_f16_snr-5_pesq1.04_1.77.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk2/f16/real_enh_ModelA_yzh_f16_snr-5_pesq1.04_1.77.wav" controls></td>
    </tr>
    <tr>
        <td><b>TriU-Net</b></td>
        <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/real_enh_TriU-Net_kkl_babble_snr-5_pesq1.09_1.7.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk1/babble/real_enh_TriU-Net_kkl_babble_snr-5_pesq1.09_1.7.wav" controls></td>
        <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/real_enh_TriU-Net_yzh_babble_snr-5_pesq1.06_1.65.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk2/babble/real_enh_TriU-Net_yzh_babble_snr-5_pesq1.06_1.65.wav" controls></td>
        <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/real_enh_TriU-Net_kkl_f16_snr-5_pesq1.06_1.84.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk1/f16/real_enh_TriU-Net_kkl_f16_snr-5_pesq1.06_1.84.wav" controls></td>
        <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/real_enh_TriU-Net_yzh_f16_snr-5_pesq1.04_1.9.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/real%20recording/spk2/f16/real_enh_TriU-Net_yzh_f16_snr-5_pesq1.04_1.9.wav" controls></td>
    </tr>
  </tbody>
  <colgroup>
    <col style="width: 5%;">
    <col style="width: 5%;">
    <col style="width: 5%;">
    <col style="width: 5%;">
  </colgroup>
</table>


<span id="more"></span>




<h2 id="Synthetic-Data"><a href="#Synthetic-Data" class="headerlink" title="Synthetic Data"></a>Synthetic Data</h2><table>
  <tbody>
    <tr>
        <th>Signals </th>
        <th>Spk 1 SNR:-5.36 dB</th>
        <th>Spk 2 SNR:-3.43 dB</th>
    </tr>
    <tr>
      <td>noisy</td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/1_sir-5.36dB_noisyR0.95_noisy.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/test%20set/spk1/1_sir-5.36dB_noisyR0.95_noisy.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/4_sir-3.43dB_noisyR0.67_noisy.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/test%20set/spk2/4_sir-3.43dB_noisyR0.67_noisy.wav" controls></td>
    </tr>
    <tr>
      <td>clean</td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/1_sir-5.36dB_noisyR0.95_clean.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/test%20set/spk1/1_sir-5.36dB_noisyR0.95_clean.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/4_sir-3.43dB_noisyR0.67_clean.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/test%20set/spk2/4_sir-3.43dB_noisyR0.67_clean.wav" controls></td>
    </tr>
    <tr>
      <td>EaBNet</td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/1_sir-5.36dB_noisyR0.95_EaBNet.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/test%20set/spk1/1_sir-5.36dB_noisyR0.95_EaBNet.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/4_sir-3.43dB_noisyR0.67_EaBNet.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/test%20set/spk2/4_sir-3.43dB_noisyR0.67_EaBNet.wav" controls></td>
    </tr>
    <tr>
      <td>FaSNet</td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/1_sir-5.36dB_noisyR0.95_FaSNet.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/test%20set/spk1/1_sir-5.36dB_noisyR0.95_FaSNet.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/4_sir-3.43dB_noisyR0.67_FaSNet.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/test%20set/spk2/4_sir-3.43dB_noisyR0.67_FaSNet.wav" controls></td>
    </tr>
    <tr>
      <td>Model A</td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/1_sir-5.36dB_noisyR0.95_ModelA.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/test%20set/spk1/1_sir-5.36dB_noisyR0.95_ModelA.wav" controls></td>
      <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/4_sir-3.43dB_noisyR0.67_ModelA.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/test%20set/spk2/4_sir-3.43dB_noisyR0.67_ModelA.wav" controls></td>
    </tr>
    <tr>
        <td><b>TriU-Net</b></td>
        <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/1_sir-5.36dB_noisyR0.95_TriU-Net.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/test%20set/spk1/1_sir-5.36dB_noisyR0.95_TriU-Net.wav" controls></td>
        <td><img src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/spectrograms/4_sir-3.43dB_noisyR0.67_TriU-Net.jpg"><audio src="https://raw.githubusercontent.com/CaA23187/TriU-Net_demo/main/test%20set/spk2/4_sir-3.43dB_noisyR0.67_TriU-Net.wav" controls></td>
    </tr>
  </tbody>
  <colgroup>
    <col style="width: 5%;">
    <col style="width: 5%;">
    <col style="width: 5%;">
    <col style="width: 5%;">
  </colgroup>
</table>











<h2 id="Other-samples"><a href="#Other-samples" class="headerlink" title="Other samples"></a>Other samples</h2><p>Other SNR scenarios  See <a href="https://github.com/CaA23187/TriU-Net_demo">https://github.com/CaA23187/TriU-Net_demo</a></p>
]]></content>
      <categories>
        <category>Speech Enhancement</category>
      </categories>
      <tags>
        <tag>Multi-Channel Speech Enhancement</tag>
        <tag>Beamforming</tag>
        <tag>Deep Neural Network</tag>
        <tag>Microphone Array</tag>
      </tags>
  </entry>
</search>
